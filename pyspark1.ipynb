{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e4864341-f954-4b3c-8b88-6ca2e78fb1b5","cell_type":"code","source":"# Install Java and Spark\n!apt-get update -y\n!apt-get install openjdk-11-jdk -y\n!wget -q https://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.2.tgz\n!tar xf spark-3.3.0-bin-hadoop3.2.tgz\n!pip install findspark\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:30:12.532192Z","iopub.execute_input":"2025-02-05T18:30:12.532574Z","iopub.status.idle":"2025-02-05T18:30:51.599594Z","shell.execute_reply.started":"2025-02-05T18:30:12.532532Z","shell.execute_reply":"2025-02-05T18:30:51.598042Z"}},"outputs":[{"name":"stdout","text":"Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\nHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \nGet:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nGet:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [62.9 kB]                 \nGet:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]               \nGet:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,306 kB]\nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nGet:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,657 kB]\nGet:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nGet:13 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]\nHit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease              \nGet:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,907 kB]\nGet:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,606 kB]              \nGet:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,606 kB]        \nGet:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,650 kB]                    \nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,742 kB]          \nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,523 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:23 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.6 kB]\nGet:24 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [57.8 kB]\nFetched 28.9 MB in 3s (8,722 kB/s)                           \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libxtst6\n  libxxf86dga1 openjdk-11-jdk-headless openjdk-11-jre openjdk-11-jre-headless x11-utils\nSuggested packages:\n  openjdk-11-demo openjdk-11-source visualvm libnss-mdns fonts-ipafont-gothic fonts-ipafont-mincho\n  fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic mesa-utils\nThe following NEW packages will be installed:\n  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libxtst6\n  libxxf86dga1 openjdk-11-jdk openjdk-11-jre x11-utils\nThe following packages will be upgraded:\n  openjdk-11-jdk-headless openjdk-11-jre-headless\n2 upgraded, 9 newly installed, 0 to remove and 115 not upgraded.\nNeed to get 121 MB of archives.\nAfter this operation, 13.3 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\nGet:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.26+4-1ubuntu1~22.04 [73.6 MB]\nGet:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre-headless amd64 11.0.26+4-1ubuntu1~22.04 [42.5 MB]\nGet:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.26+4-1ubuntu1~22.04 [214 kB]\nGet:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.26+4-1ubuntu1~22.04 [1,341 kB]\nFetched 121 MB in 5s (25.6 MB/s)           \nSelecting previously unselected package fonts-dejavu-core.\n(Reading database ... 127400 files and directories currently installed.)\nPreparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\nUnpacking fonts-dejavu-core (2.37-2build1) ...\nSelecting previously unselected package fonts-dejavu-extra.\nPreparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\nUnpacking fonts-dejavu-extra (2.37-2build1) ...\nSelecting previously unselected package libxtst6:amd64.\nPreparing to unpack .../02-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\nUnpacking libxtst6:amd64 (2:1.2.3-1build4) ...\nSelecting previously unselected package libxxf86dga1:amd64.\nPreparing to unpack .../03-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\nUnpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\nSelecting previously unselected package x11-utils.\nPreparing to unpack .../04-x11-utils_7.7+5build2_amd64.deb ...\nUnpacking x11-utils (7.7+5build2) ...\nSelecting previously unselected package libatk-wrapper-java.\nPreparing to unpack .../05-libatk-wrapper-java_0.38.0-5build1_all.deb ...\nUnpacking libatk-wrapper-java (0.38.0-5build1) ...\nSelecting previously unselected package libatk-wrapper-java-jni:amd64.\nPreparing to unpack .../06-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\nUnpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\nPreparing to unpack .../07-openjdk-11-jdk-headless_11.0.26+4-1ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jdk-headless:amd64 (11.0.26+4-1ubuntu1~22.04) over (11.0.25+9-1ubuntu1~22.04) ...\nPreparing to unpack .../08-openjdk-11-jre-headless_11.0.26+4-1ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jre-headless:amd64 (11.0.26+4-1ubuntu1~22.04) over (11.0.25+9-1ubuntu1~22.04) ...\nSelecting previously unselected package openjdk-11-jre:amd64.\nPreparing to unpack .../09-openjdk-11-jre_11.0.26+4-1ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jre:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nSelecting previously unselected package openjdk-11-jdk:amd64.\nPreparing to unpack .../10-openjdk-11-jdk_11.0.26+4-1ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jdk:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nSetting up libxtst6:amd64 (2:1.2.3-1build4) ...\nSetting up openjdk-11-jre-headless:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nSetting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\nSetting up openjdk-11-jre:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nSetting up openjdk-11-jdk-headless:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nSetting up fonts-dejavu-core (2.37-2build1) ...\nSetting up fonts-dejavu-extra (2.37-2build1) ...\nSetting up x11-utils (7.7+5build2) ...\nSetting up openjdk-11-jdk:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\nSetting up libatk-wrapper-java (0.38.0-5build1) ...\nSetting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.4) ...\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\ntar: spark-3.3.0-bin-hadoop3.2.tgz: Cannot open: No such file or directory\ntar: Error is not recoverable: exiting now\nCollecting findspark\n  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\nDownloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\nInstalling collected packages: findspark\nSuccessfully installed findspark-2.0.1\n","output_type":"stream"}],"execution_count":1},{"id":"e6eb3916","cell_type":"code","source":"!pip install pyspark findspark pandas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:30:51.601505Z","iopub.execute_input":"2025-02-05T18:30:51.601887Z","iopub.status.idle":"2025-02-05T18:30:55.855385Z","shell.execute_reply.started":"2025-02-05T18:30:51.601839Z","shell.execute_reply":"2025-02-05T18:30:55.853953Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\nRequirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\nRequirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"id":"55769eb6","cell_type":"code","source":"# Step 1: Initialize PySpark\nimport findspark\nfindspark.init()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:30:55.857538Z","iopub.execute_input":"2025-02-05T18:30:55.857897Z","iopub.status.idle":"2025-02-05T18:30:56.333109Z","shell.execute_reply.started":"2025-02-05T18:30:55.857866Z","shell.execute_reply":"2025-02-05T18:30:56.332103Z"}},"outputs":[],"execution_count":3},{"id":"5a535ddb-335d-4d4e-8c2f-b5083a1475ee","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4b2b16a2","cell_type":"code","source":"# Step 2: Import Necessary Libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, count, when, isnan, avg, sum, min, max, desc, row_number\nfrom pyspark.sql.window import Window\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:30:56.334099Z","iopub.execute_input":"2025-02-05T18:30:56.334562Z","iopub.status.idle":"2025-02-05T18:30:56.677510Z","shell.execute_reply.started":"2025-02-05T18:30:56.334520Z","shell.execute_reply":"2025-02-05T18:30:56.676313Z"}},"outputs":[],"execution_count":4},{"id":"fb6ebaba","cell_type":"code","source":"\n\n# Create a Spark session\nspark = SparkSession.builder.master(\"local[2]\").appName(\"TitanicAnalysis\").getOrCreate()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:30:56.678707Z","iopub.execute_input":"2025-02-05T18:30:56.679131Z","iopub.status.idle":"2025-02-05T18:31:04.014347Z","shell.execute_reply.started":"2025-02-05T18:30:56.679102Z","shell.execute_reply":"2025-02-05T18:31:04.012420Z"}},"outputs":[],"execution_count":5},{"id":"3d0cfb4f-3360-46d8-84cd-90b51fb99b99","cell_type":"code","source":"!wget https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:04.018811Z","iopub.execute_input":"2025-02-05T18:31:04.019367Z","iopub.status.idle":"2025-02-05T18:31:04.359242Z","shell.execute_reply.started":"2025-02-05T18:31:04.019303Z","shell.execute_reply":"2025-02-05T18:31:04.357961Z"}},"outputs":[{"name":"stdout","text":"--2025-02-05 18:31:04--  https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 60302 (59K) [text/plain]\nSaving to: ‘titanic.csv’\n\ntitanic.csv         100%[===================>]  58.89K  --.-KB/s    in 0.008s  \n\n2025-02-05 18:31:04 (7.46 MB/s) - ‘titanic.csv’ saved [60302/60302]\n\n","output_type":"stream"}],"execution_count":6},{"id":"d97740c6","cell_type":"code","source":"# Load Titanic dataset from local file\ndf = spark.read.csv('titanic.csv', header=True, inferSchema=True)\ndf.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:04.361334Z","iopub.execute_input":"2025-02-05T18:31:04.361803Z","iopub.status.idle":"2025-02-05T18:31:13.393639Z","shell.execute_reply.started":"2025-02-05T18:31:04.361762Z","shell.execute_reply":"2025-02-05T18:31:13.390846Z"}},"outputs":[{"name":"stdout","text":"+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|\n|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|\n|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|\n|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|\n|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|\n|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n","output_type":"stream"}],"execution_count":7},{"id":"fefcacc5","cell_type":"code","source":"# Step 5: Display First 5 Rows\ndf.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:13.394568Z","iopub.execute_input":"2025-02-05T18:31:13.394941Z","iopub.status.idle":"2025-02-05T18:31:13.631724Z","shell.execute_reply.started":"2025-02-05T18:31:13.394904Z","shell.execute_reply":"2025-02-05T18:31:13.630408Z"}},"outputs":[{"name":"stdout","text":"+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":8},{"id":"fb183157","cell_type":"code","source":"# Step 6: Print Schema\ndf.printSchema()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:13.632628Z","iopub.execute_input":"2025-02-05T18:31:13.633022Z","iopub.status.idle":"2025-02-05T18:31:13.642030Z","shell.execute_reply.started":"2025-02-05T18:31:13.632987Z","shell.execute_reply":"2025-02-05T18:31:13.641159Z"}},"outputs":[{"name":"stdout","text":"root\n |-- PassengerId: integer (nullable = true)\n |-- Survived: integer (nullable = true)\n |-- Pclass: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- SibSp: integer (nullable = true)\n |-- Parch: integer (nullable = true)\n |-- Ticket: string (nullable = true)\n |-- Fare: double (nullable = true)\n |-- Cabin: string (nullable = true)\n |-- Embarked: string (nullable = true)\n\n","output_type":"stream"}],"execution_count":9},{"id":"2ac7eb25","cell_type":"code","source":"# Step 7: Count Total Rows and Columns\nprint(f\"Total Rows: {df.count()}, Total Columns: {len(df.columns)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:13.644038Z","iopub.execute_input":"2025-02-05T18:31:13.644534Z","iopub.status.idle":"2025-02-05T18:31:14.503587Z","shell.execute_reply.started":"2025-02-05T18:31:13.644453Z","shell.execute_reply":"2025-02-05T18:31:14.501802Z"}},"outputs":[{"name":"stdout","text":"Total Rows: 891, Total Columns: 12\n","output_type":"stream"}],"execution_count":10},{"id":"fc347eab","cell_type":"code","source":"# Step 8: Display Summary Statistics\ndf.describe().show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:14.506238Z","iopub.execute_input":"2025-02-05T18:31:14.506731Z","iopub.status.idle":"2025-02-05T18:31:17.120321Z","shell.execute_reply.started":"2025-02-05T18:31:14.506688Z","shell.execute_reply":"2025-02-05T18:31:17.118684Z"}},"outputs":[{"name":"stdout","text":"+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                NULL|  NULL| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| NULL|    NULL|\n| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                NULL|  NULL|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| NULL|    NULL|\n|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n\n","output_type":"stream"}],"execution_count":11},{"id":"1dca08d8","cell_type":"code","source":"# Step 9: Check for Missing Values\ndf.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:17.121972Z","iopub.execute_input":"2025-02-05T18:31:17.122565Z","iopub.status.idle":"2025-02-05T18:31:17.696744Z","shell.execute_reply.started":"2025-02-05T18:31:17.122519Z","shell.execute_reply":"2025-02-05T18:31:17.695287Z"}},"outputs":[{"name":"stdout","text":"+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n\n","output_type":"stream"}],"execution_count":12},{"id":"4e8531a0","cell_type":"code","source":"# Step 10: Fill Missing Values\ndf = df.fillna({'Age': df.select(avg(col(\"Age\"))).collect()[0][0], 'Embarked': 'Unknown'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:17.698578Z","iopub.execute_input":"2025-02-05T18:31:17.699056Z","iopub.status.idle":"2025-02-05T18:31:18.108581Z","shell.execute_reply.started":"2025-02-05T18:31:17.699009Z","shell.execute_reply":"2025-02-05T18:31:18.107411Z"}},"outputs":[],"execution_count":13},{"id":"1847cc46","cell_type":"code","source":"# Step 11: Select Specific Columns\ndf_selected = df.select(\"PassengerId\", \"Name\", \"Sex\", \"Age\", \"Fare\", \"Pclass\", \"Survived\")\ndf_selected.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:18.109454Z","iopub.execute_input":"2025-02-05T18:31:18.109865Z","iopub.status.idle":"2025-02-05T18:31:18.361794Z","shell.execute_reply.started":"2025-02-05T18:31:18.109826Z","shell.execute_reply":"2025-02-05T18:31:18.360707Z"}},"outputs":[{"name":"stdout","text":"+-----------+--------------------+------+----+-------+------+--------+\n|PassengerId|                Name|   Sex| Age|   Fare|Pclass|Survived|\n+-----------+--------------------+------+----+-------+------+--------+\n|          1|Braund, Mr. Owen ...|  male|22.0|   7.25|     3|       0|\n|          2|Cumings, Mrs. Joh...|female|38.0|71.2833|     1|       1|\n|          3|Heikkinen, Miss. ...|female|26.0|  7.925|     3|       1|\n|          4|Futrelle, Mrs. Ja...|female|35.0|   53.1|     1|       1|\n|          5|Allen, Mr. Willia...|  male|35.0|   8.05|     3|       0|\n+-----------+--------------------+------+----+-------+------+--------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":14},{"id":"c5671cad","cell_type":"code","source":"# Step 12: Filter Data (Passengers with Age > 18 and Fare > 50)\ndf_filtered = df_selected.filter((col(\"Age\") > 18) & (col(\"Fare\") > 50))\ndf_filtered.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:18.362663Z","iopub.execute_input":"2025-02-05T18:31:18.363130Z","iopub.status.idle":"2025-02-05T18:31:18.721008Z","shell.execute_reply.started":"2025-02-05T18:31:18.363089Z","shell.execute_reply":"2025-02-05T18:31:18.718840Z"}},"outputs":[{"name":"stdout","text":"+-----------+--------------------+------+-----------------+--------+------+--------+\n|PassengerId|                Name|   Sex|              Age|    Fare|Pclass|Survived|\n+-----------+--------------------+------+-----------------+--------+------+--------+\n|          2|Cumings, Mrs. Joh...|female|             38.0| 71.2833|     1|       1|\n|          4|Futrelle, Mrs. Ja...|female|             35.0|    53.1|     1|       1|\n|          7|McCarthy, Mr. Tim...|  male|             54.0| 51.8625|     1|       0|\n|         28|Fortune, Mr. Char...|  male|             19.0|   263.0|     1|       0|\n|         32|Spencer, Mrs. Wil...|female|29.69911764705882|146.5208|     1|       1|\n+-----------+--------------------+------+-----------------+--------+------+--------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":15},{"id":"a9a1ad50","cell_type":"code","source":"# Step 13: Group By & Aggregation (Survival Rate by Gender)\ndf_grouped = df.groupBy(\"Sex\").agg(avg(\"Survived\").alias(\"Survival Rate\")).orderBy(desc(\"Survival Rate\"))\ndf_grouped.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:18.722818Z","iopub.execute_input":"2025-02-05T18:31:18.723291Z","iopub.status.idle":"2025-02-05T18:31:19.600460Z","shell.execute_reply.started":"2025-02-05T18:31:18.723244Z","shell.execute_reply":"2025-02-05T18:31:19.599525Z"}},"outputs":[{"name":"stdout","text":"+------+-------------------+\n|   Sex|      Survival Rate|\n+------+-------------------+\n|female| 0.7420382165605095|\n|  male|0.18890814558058924|\n+------+-------------------+\n\n","output_type":"stream"}],"execution_count":16},{"id":"11fce08c","cell_type":"code","source":"# Step 14: Use SQL in PySpark (Convert DataFrame to SQL Table)\ndf.createOrReplaceTempView(\"titanic\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:19.602774Z","iopub.execute_input":"2025-02-05T18:31:19.603223Z","iopub.status.idle":"2025-02-05T18:31:19.662188Z","shell.execute_reply.started":"2025-02-05T18:31:19.603177Z","shell.execute_reply":"2025-02-05T18:31:19.660965Z"}},"outputs":[],"execution_count":17},{"id":"de9481ca","cell_type":"code","source":"# Step 15: Run SQL Query (Top 5 Oldest Passengers)\nspark.sql(\"SELECT Name, Age, Pclass FROM titanic ORDER BY Age DESC LIMIT 5\").show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:19.667380Z","iopub.execute_input":"2025-02-05T18:31:19.667805Z","iopub.status.idle":"2025-02-05T18:31:20.000216Z","shell.execute_reply.started":"2025-02-05T18:31:19.667769Z","shell.execute_reply":"2025-02-05T18:31:19.998409Z"}},"outputs":[{"name":"stdout","text":"+--------------------+----+------+\n|                Name| Age|Pclass|\n+--------------------+----+------+\n|Barkworth, Mr. Al...|80.0|     1|\n| Svensson, Mr. Johan|74.0|     3|\n|Artagaveytia, Mr....|71.0|     1|\n|Goldschmidt, Mr. ...|71.0|     1|\n|Connors, Mr. Patrick|70.5|     3|\n+--------------------+----+------+\n\n","output_type":"stream"}],"execution_count":18},{"id":"87bd3523","cell_type":"code","source":"# Step 16: Join Operation (Self Join Example on Same Dataset)\ndf_joined = df.alias(\"df1\").join(df.alias(\"df2\"), col(\"df1.Pclass\") == col(\"df2.Pclass\"), \"inner\")\ndf_joined.select(\"df1.Name\", \"df2.Name\", \"df1.Pclass\").show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:20.002473Z","iopub.execute_input":"2025-02-05T18:31:20.002947Z","iopub.status.idle":"2025-02-05T18:31:20.580731Z","shell.execute_reply.started":"2025-02-05T18:31:20.002909Z","shell.execute_reply":"2025-02-05T18:31:20.579546Z"}},"outputs":[{"name":"stdout","text":"+--------------------+--------------------+------+\n|                Name|                Name|Pclass|\n+--------------------+--------------------+------+\n|Braund, Mr. Owen ...| Dooley, Mr. Patrick|     3|\n|Braund, Mr. Owen ...|\"Johnston, Miss. ...|     3|\n|Braund, Mr. Owen ...|Rice, Mrs. Willia...|     3|\n|Braund, Mr. Owen ...|Sutehall, Mr. Hen...|     3|\n|Braund, Mr. Owen ...|Dahlberg, Miss. G...|     3|\n+--------------------+--------------------+------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":19},{"id":"b745415b","cell_type":"code","source":"# Step 17: Window Function (Ranking Passengers by Fare)\nwindowSpec = Window.orderBy(desc(\"Fare\"))\ndf_with_rank = df.withColumn(\"Rank\", row_number().over(windowSpec))\ndf_with_rank.select(\"Name\", \"Fare\", \"Rank\").show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:20.581731Z","iopub.execute_input":"2025-02-05T18:31:20.582138Z","iopub.status.idle":"2025-02-05T18:31:21.020420Z","shell.execute_reply.started":"2025-02-05T18:31:20.582099Z","shell.execute_reply":"2025-02-05T18:31:21.018770Z"}},"outputs":[{"name":"stdout","text":"+--------------------+--------+----+\n|                Name|    Fare|Rank|\n+--------------------+--------+----+\n|    Ward, Miss. Anna|512.3292|   1|\n|Cardeza, Mr. Thom...|512.3292|   2|\n|Lesurer, Mr. Gust...|512.3292|   3|\n|Fortune, Miss. Ma...|   263.0|   4|\n|Fortune, Mr. Char...|   263.0|   5|\n+--------------------+--------+----+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":20},{"id":"b8ac3da8","cell_type":"code","source":"# Step 18: Convert PySpark DataFrame to Pandas\npandas_df = df.toPandas()\nprint(pandas_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:21.021404Z","iopub.execute_input":"2025-02-05T18:31:21.024939Z","iopub.status.idle":"2025-02-05T18:31:21.299181Z","shell.execute_reply.started":"2025-02-05T18:31:21.024852Z","shell.execute_reply":"2025-02-05T18:31:21.297943Z"}},"outputs":[{"name":"stdout","text":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500  None        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250  None        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500  None        S  \n","output_type":"stream"}],"execution_count":21},{"id":"1c6ca616","cell_type":"code","source":"# Step 19: Convert Pandas DataFrame to PySpark\nspark_df_from_pandas = spark.createDataFrame(pandas_df)\nspark_df_from_pandas.show(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:21.300062Z","iopub.execute_input":"2025-02-05T18:31:21.300426Z","iopub.status.idle":"2025-02-05T18:31:22.748794Z","shell.execute_reply.started":"2025-02-05T18:31:21.300391Z","shell.execute_reply":"2025-02-05T18:31:22.747669Z"}},"outputs":[{"name":"stdout","text":"+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":22},{"id":"8a36f870","cell_type":"code","source":"# Step 20: Save Processed Data to a CSV File\ndf.write.csv(\"processed_titanic.csv\", header=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:22.749927Z","iopub.execute_input":"2025-02-05T18:31:22.750311Z","iopub.status.idle":"2025-02-05T18:31:23.182555Z","shell.execute_reply.started":"2025-02-05T18:31:22.750269Z","shell.execute_reply":"2025-02-05T18:31:23.181483Z"}},"outputs":[],"execution_count":23},{"id":"54913220","cell_type":"code","source":"# Step 21: Stop Spark Session\nspark.stop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:23.183333Z","iopub.execute_input":"2025-02-05T18:31:23.183689Z","iopub.status.idle":"2025-02-05T18:31:23.738083Z","shell.execute_reply.started":"2025-02-05T18:31:23.183653Z","shell.execute_reply":"2025-02-05T18:31:23.736929Z"}},"outputs":[],"execution_count":24},{"id":"50643cdc","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5341fa97","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"951ebeb3","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6a7cf332","cell_type":"code","source":"import pandas as pd\nimport time\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\n\nspark = SparkSession.builder.appName(\"SpeedTest\").getOrCreate()\n\n# Creating a large dataset (1 million rows)\ndata = {\"id\": range(1, 1000001), \"value\": range(1000000, 2000000)}  # Adjusted the range for 'value'\n\n# Pandas Test\nstart_time = time.time()\ndf_pandas = pd.DataFrame(data)\ndf_pandas[\"value_squared\"] = df_pandas[\"value\"] ** 2  # Squaring a column\nprint(\"Pandas Time:\", time.time() - start_time, \"seconds\")\n\n# PySpark Test\nstart_time = time.time()\ndf_spark = spark.createDataFrame(pd.DataFrame(data))\ndf_spark = df_spark.withColumn(\"value_squared\", col(\"value\") ** 2)  # Squaring a column\ndf_spark.show(5)\nprint(\"PySpark Time:\", time.time() - start_time, \"seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:23.739140Z","iopub.execute_input":"2025-02-05T18:31:23.739434Z","iopub.status.idle":"2025-02-05T18:31:45.547445Z","shell.execute_reply.started":"2025-02-05T18:31:23.739407Z","shell.execute_reply":"2025-02-05T18:31:45.546362Z"}},"outputs":[{"name":"stdout","text":"Pandas Time: 0.04015064239501953 seconds\n+---+-------+-----------------+\n| id|  value|    value_squared|\n+---+-------+-----------------+\n|  1|1000000|           1.0E12|\n|  2|1000001|1.000002000001E12|\n|  3|1000002|1.000004000004E12|\n|  4|1000003|1.000006000009E12|\n|  5|1000004|1.000008000016E12|\n+---+-------+-----------------+\nonly showing top 5 rows\n\nPySpark Time: 21.550978660583496 seconds\n","output_type":"stream"}],"execution_count":25},{"id":"5df4df9a-83e8-44b7-967c-6f9a8f8fcd87","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"225416c6-3a2d-43a8-8ca1-a7e929b645c3","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d1ed2b04-5022-436e-89b5-8c697b13002a","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e3ab3aaa-9fba-44f9-9e2d-29d57b777c31","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\n\n# Simulating data for 10 million transactions\nn_rows = 10000000\ndata = {\n    \"customer_id\": np.random.randint(1, 500000, size=n_rows),\n    \"product_id\": np.random.randint(1, 10000, size=n_rows),\n    \"timestamp\": [datetime.now() - timedelta(days=np.random.randint(0, 30)) for _ in range(n_rows)],\n    \"quantity\": np.random.randint(1, 10, size=n_rows),\n    \"price\": np.random.uniform(5, 500, size=n_rows),\n    \"category\": np.random.choice(['Electronics', 'Clothing', 'Home', 'Books', 'Beauty'], size=n_rows),\n    \"store_location\": np.random.choice(['NY', 'LA', 'SF', 'Chicago'], size=n_rows),\n    \"payment_method\": np.random.choice(['Credit', 'Debit', 'PayPal', 'Cash'], size=n_rows)\n}\n\ndf = pd.DataFrame(data)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:31:45.548248Z","iopub.execute_input":"2025-02-05T18:31:45.548639Z","iopub.status.idle":"2025-02-05T18:32:59.977972Z","shell.execute_reply.started":"2025-02-05T18:31:45.548600Z","shell.execute_reply":"2025-02-05T18:32:59.976834Z"}},"outputs":[],"execution_count":26},{"id":"efae00a5-8fbd-4597-a82d-cfa36eaeac52","cell_type":"code","source":"# Save to CSV for later use in PySpark\ndf.to_csv('large_ecommerce_transactions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:32:59.979064Z","iopub.execute_input":"2025-02-05T18:32:59.979322Z","iopub.status.idle":"2025-02-05T18:34:01.242911Z","shell.execute_reply.started":"2025-02-05T18:32:59.979299Z","shell.execute_reply":"2025-02-05T18:34:01.241669Z"}},"outputs":[],"execution_count":27},{"id":"a7845396-4b34-412c-a1c3-395a7e15066e","cell_type":"code","source":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"EcommerceAnalysis\").getOrCreate()\n\n# Load the data into PySpark DataFrame\ndf_spark = spark.read.csv(\"large_ecommerce_transactions.csv\", header=True, inferSchema=True)\n\n# Show the schema to verify\ndf_spark.printSchema()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:34:01.244219Z","iopub.execute_input":"2025-02-05T18:34:01.244681Z","iopub.status.idle":"2025-02-05T18:34:19.950027Z","shell.execute_reply.started":"2025-02-05T18:34:01.244637Z","shell.execute_reply":"2025-02-05T18:34:19.948847Z"}},"outputs":[{"name":"stdout","text":"root\n |-- customer_id: integer (nullable = true)\n |-- product_id: integer (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- quantity: integer (nullable = true)\n |-- price: double (nullable = true)\n |-- category: string (nullable = true)\n |-- store_location: string (nullable = true)\n |-- payment_method: string (nullable = true)\n\n","output_type":"stream"}],"execution_count":28},{"id":"0d5de375-e44c-4d95-b6ef-7b260a5c7141","cell_type":"code","source":"from pyspark.sql.functions import sum, avg, count\n\n# Calculate total spend per customer\ncustomer_spend = df_spark.groupBy(\"customer_id\").agg(\n    sum(\"price\").alias(\"total_spent\"),\n    count(\"product_id\").alias(\"purchase_count\"),\n    avg(\"price\").alias(\"avg_spent_per_item\")\n)\n\n# Show top 10 customers by total spend\ncustomer_spend.orderBy(\"total_spent\", ascending=False).show(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:34:19.951145Z","iopub.execute_input":"2025-02-05T18:34:19.951537Z","iopub.status.idle":"2025-02-05T18:34:41.880705Z","shell.execute_reply.started":"2025-02-05T18:34:19.951478Z","shell.execute_reply":"2025-02-05T18:34:41.877684Z"}},"outputs":[{"name":"stdout","text":"+-----------+------------------+--------------+------------------+\n|customer_id|       total_spent|purchase_count|avg_spent_per_item|\n+-----------+------------------+--------------+------------------+\n|      92892|11962.376586247785|            40|299.05941465619463|\n|     182598|11734.744080147044|            40| 293.3686020036761|\n|     423768|11640.544138920972|            41|283.91571070538953|\n|     146391|11455.111367612324|            40| 286.3777841903081|\n|      16667| 11356.46996053375|            38|  298.854472645625|\n|     138550| 11314.97826394082|            36| 314.3049517761339|\n|     211963|11208.079202264254|            39|287.38664621190395|\n|      92659|  11197.7613731752|            33|339.32610221743033|\n|     136212|11183.620709482999|            38| 294.3058081442894|\n|     242070| 11154.96383273799|            36| 309.8601064649442|\n+-----------+------------------+--------------+------------------+\nonly showing top 10 rows\n\n","output_type":"stream"}],"execution_count":29},{"id":"067cc6db-5f6b-4c71-b7c5-27a6d7be6ee0","cell_type":"code","source":"# Group by product and category to find the most popular products\nproduct_sales = df_spark.groupBy(\"product_id\", \"category\").agg(\n    sum(\"quantity\").alias(\"total_sales\"),\n    sum(\"price\").alias(\"total_revenue\")\n).orderBy(\"total_sales\", ascending=False)\n\nproduct_sales.show(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:34:41.881729Z","iopub.execute_input":"2025-02-05T18:34:41.882089Z","iopub.status.idle":"2025-02-05T18:34:58.538090Z","shell.execute_reply.started":"2025-02-05T18:34:41.882052Z","shell.execute_reply":"2025-02-05T18:34:58.536328Z"}},"outputs":[{"name":"stdout","text":"+----------+-----------+-----------+------------------+\n|product_id|   category|total_sales|     total_revenue|\n+----------+-----------+-----------+------------------+\n|      8039|     Beauty|       1346|64675.532696662136|\n|      2170|       Home|       1336| 64479.52902103612|\n|      2403|      Books|       1326|  62125.4629707797|\n|      9884|     Beauty|       1320|64735.875146384584|\n|      1166|Electronics|       1320| 69041.05813436535|\n|      3991|   Clothing|       1319|60501.681785976296|\n|       624|      Books|       1312|   62133.655756085|\n|       873|   Clothing|       1302| 63056.01226189673|\n|      1984|     Beauty|       1295| 62769.96621621522|\n|      4812|   Clothing|       1289| 59532.93994021196|\n+----------+-----------+-----------+------------------+\nonly showing top 10 rows\n\n","output_type":"stream"}],"execution_count":30},{"id":"33efac8c-6ed6-4ec7-8dbf-0c1dabee1bd0","cell_type":"code","source":"from pyspark.sql.functions import hour\n\n# Extract hour from timestamp\ndf_spark = df_spark.withColumn(\"hour\", hour(\"timestamp\"))\n\n# Group by hour of day to find peak sales hours\nsales_by_hour = df_spark.groupBy(\"hour\").agg(\n    sum(\"quantity\").alias(\"total_sales\"),\n    sum(\"price\").alias(\"total_revenue\")\n).orderBy(\"total_sales\", ascending=False)\n\nsales_by_hour.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:34:58.539481Z","iopub.execute_input":"2025-02-05T18:34:58.539906Z","iopub.status.idle":"2025-02-05T18:35:12.919303Z","shell.execute_reply.started":"2025-02-05T18:34:58.539860Z","shell.execute_reply":"2025-02-05T18:35:12.918150Z"}},"outputs":[{"name":"stdout","text":"+----+-----------+--------------------+\n|hour|total_sales|       total_revenue|\n+----+-----------+--------------------+\n|  18|   49993455|2.5252163586712136E9|\n+----+-----------+--------------------+\n\n","output_type":"stream"}],"execution_count":31},{"id":"56c0a7ea-496a-4357-b172-96cf297f09a5","cell_type":"code","source":"from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Prepare the data for ALS model\nratings_df = df_spark.select(\"customer_id\", \"product_id\", \"price\").withColumnRenamed(\"price\", \"rating\")\n\n# Train a collaborative filtering model using ALS\nals = ALS(userCol=\"customer_id\", itemCol=\"product_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\nmodel = als.fit(ratings_df)\n\n# Make recommendations for all customers\nrecommendations = model.recommendForAllUsers(5)\nrecommendations.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:35:12.921325Z","iopub.execute_input":"2025-02-05T18:35:12.922520Z","iopub.status.idle":"2025-02-05T18:40:27.556177Z","shell.execute_reply.started":"2025-02-05T18:35:12.922444Z","shell.execute_reply":"2025-02-05T18:40:27.553633Z"}},"outputs":[{"name":"stdout","text":"+-----------+--------------------+\n|customer_id|     recommendations|\n+-----------+--------------------+\n|          1|[{1820, 692.85736...|\n|         12|[{5281, 634.515},...|\n|         22|[{2187, 996.1738}...|\n|         26|[{4699, 1074.7286...|\n|         27|[{30, 756.7236}, ...|\n|         28|[{6433, 733.2334}...|\n|         31|[{6532, 1391.7119...|\n|         34|[{591, 905.0293},...|\n|         44|[{3387, 686.19855...|\n|         47|[{9562, 1071.4802...|\n|         53|[{9736, 1379.1587...|\n|         65|[{3954, 1473.2566...|\n|         76|[{2505, 1062.7957...|\n|         78|[{8944, 1236.5356...|\n|         81|[{278, 1429.5459}...|\n|         85|[{2559, 918.63165...|\n|         91|[{4283, 1200.3527...|\n|         93|[{4610, 1492.9758...|\n|        101|[{5447, 862.263},...|\n|        103|[{2637, 618.62366...|\n+-----------+--------------------+\nonly showing top 20 rows\n\n","output_type":"stream"}],"execution_count":32},{"id":"40ca902c-e8b6-4269-8970-28a7a0c19188","cell_type":"code","source":"evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\npredictions = model.transform(ratings_df)\nrmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error (RMSE) for recommendation:\", rmse)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T18:40:27.558855Z","iopub.execute_input":"2025-02-05T18:40:27.561314Z","iopub.status.idle":"2025-02-05T18:41:12.540466Z","shell.execute_reply.started":"2025-02-05T18:40:27.561247Z","shell.execute_reply":"2025-02-05T18:41:12.539019Z"}},"outputs":[{"name":"stdout","text":"Root-mean-square error (RMSE) for recommendation: 97.36442893415366\n","output_type":"stream"}],"execution_count":33},{"id":"cfe9750b-ebe8-4d76-b0a3-b204e5215423","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d9ea2e91-6416-4ac4-b9f4-dbbdca3223ab","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f352c225-303b-46d4-885b-3a7fc2601f94","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}